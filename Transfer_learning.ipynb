{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9cb9fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'TypeAliasType' could not be imported from 'c:\\Users\\SUBHRADIP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\typing_extensions.py'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "import PIL.Image as Image\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03dadb1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tf_keras.src.backend' has no attribute 'floatx'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m IMAGE_SHAPE = (\u001b[32m224\u001b[39m, \u001b[32m224\u001b[39m)\n\u001b[32m      3\u001b[39m classifier = tf.keras.Sequential([\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mhub\u001b[49m\u001b[43m.\u001b[49m\u001b[43mKerasLayer\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m=\u001b[49m\u001b[43mIMAGE_SHAPE\u001b[49m\u001b[43m+\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m ])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SUBHRADIP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\keras_layer.py:184\u001b[39m, in \u001b[36mKerasLayer.__init__\u001b[39m\u001b[34m(self, handle, trainable, arguments, _sentinel, tags, signature, signature_outputs_as_dict, output_key, output_shape, load_options, **kwargs)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28mself\u001b[39m._callable = \u001b[38;5;28mself\u001b[39m._get_callable()\n\u001b[32m    183\u001b[39m \u001b[38;5;28mself\u001b[39m._has_training_argument = func_has_training_argument(\u001b[38;5;28mself\u001b[39m._callable)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_setup_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SUBHRADIP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow_hub\\keras_layer.py:189\u001b[39m, in \u001b[36mKerasLayer._setup_layer\u001b[39m\u001b[34m(self, trainable, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Constructs keras layer with relevant weights and losses.\"\"\"\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[38;5;66;03m# Initialize an empty layer, then add_weight() etc. as needed.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[38;5;66;03m# Add trainable and non-trainable weights from the callable.\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._func, \u001b[33m\"\u001b[39m\u001b[33mtrainable_variables\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SUBHRADIP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[39m, in \u001b[36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28mself\u001b[39m._self_setattr_tracking = \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m   result = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    206\u001b[39m   \u001b[38;5;28mself\u001b[39m._self_setattr_tracking = previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SUBHRADIP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py:394\u001b[39m, in \u001b[36mLayer.__init__\u001b[39m\u001b[34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28mself\u001b[39m._metrics_lock = threading.Lock()\n\u001b[32m    389\u001b[39m \u001b[38;5;66;03m# Note that models also have a dtype policy, as they are layers. For\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[38;5;66;03m# functional models, the policy is only used in Model.compile, which\u001b[39;00m\n\u001b[32m    391\u001b[39m \u001b[38;5;66;03m# wraps the optimizer with a LossScaleOptimizer if the policy name is\u001b[39;00m\n\u001b[32m    392\u001b[39m \u001b[38;5;66;03m# \"mixed_float16\". Subclassed models additionally use the policy's\u001b[39;00m\n\u001b[32m    393\u001b[39m \u001b[38;5;66;03m# compute and variable dtypes, as like any ordinary layer.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_dtype_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;66;03m# Boolean indicating whether the layer automatically casts its inputs to\u001b[39;00m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# the layer's compute_dtype.\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;28mself\u001b[39m._autocast = kwargs.get(\n\u001b[32m    398\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mautocast\u001b[39m\u001b[33m\"\u001b[39m, base_layer_utils.v2_dtype_behavior_enabled()\n\u001b[32m    399\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SUBHRADIP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\engine\\base_layer.py:2696\u001b[39m, in \u001b[36mLayer._set_dtype_policy\u001b[39m\u001b[34m(self, dtype)\u001b[39m\n\u001b[32m   2694\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_dtype_policy\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype):\n\u001b[32m   2695\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Sets self._dtype_policy.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2696\u001b[39m     \u001b[38;5;28mself\u001b[39m._dtype_policy = \u001b[43mpolicy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2698\u001b[39m     \u001b[38;5;66;03m# Performance optimization: cache the compute dtype as a Dtype object or\u001b[39;00m\n\u001b[32m   2699\u001b[39m     \u001b[38;5;66;03m# None, so that str to Dtype conversion doesn't happen in\u001b[39;00m\n\u001b[32m   2700\u001b[39m     \u001b[38;5;66;03m# Layer.__call__.\u001b[39;00m\n\u001b[32m   2701\u001b[39m     \u001b[38;5;66;03m# TODO(b/157486353): Investigate returning DTypes in Policy.\u001b[39;00m\n\u001b[32m   2702\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dtype_policy.compute_dtype:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SUBHRADIP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\mixed_precision\\policy.py:483\u001b[39m, in \u001b[36mget_policy\u001b[39m\u001b[34m(identifier)\u001b[39m\n\u001b[32m    481\u001b[39m     dtype_policy = Policy(tf.as_dtype(identifier).name)\n\u001b[32m    482\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m     dtype_policy = \u001b[43mglobal_policy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    485\u001b[39m     dtype_policy.name == \u001b[33m\"\u001b[39m\u001b[33mmixed_float16\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    486\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m loss_scale_optimizer.strategy_supports_loss_scaling()\n\u001b[32m   (...)\u001b[39m\u001b[32m    490\u001b[39m     \u001b[38;5;66;03m# unsupported strategies. This is because 'mixed_float16' requires\u001b[39;00m\n\u001b[32m    491\u001b[39m     \u001b[38;5;66;03m# loss scaling for numeric stability.\u001b[39;00m\n\u001b[32m    492\u001b[39m     strategy = tf.distribute.get_strategy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SUBHRADIP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\mixed_precision\\policy.py:360\u001b[39m, in \u001b[36mglobal_policy\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_policy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    359\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m base_layer_utils.v2_dtype_behavior_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m Policy(\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloatx\u001b[49m())\n\u001b[32m    361\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    362\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m Policy(\u001b[33m\"\u001b[39m\u001b[33m_infer\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'tf_keras.src.backend' has no attribute 'floatx'"
     ]
    }
   ],
   "source": [
    "IMAGE_SHAPE = (224, 224)\n",
    "\n",
    "classifier = tf.keras.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\", input_shape=IMAGE_SHAPE+(3,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472447e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
